---
layout: post
author: Thomas
title: MPI指南
header-style: text
catalog: true
tags: 
  - 并行计算
---


## 什么是MPICH

MPICH（Message Passing Interface CH）是一种**高性能的消息传递接口**实现，广泛用于并行计算中。它允许多个计算机节点（通常是多核处理器）通过消息传递的方式协同工作，从而解决大规模计算问题。

## 环境搭建

使用的是`ubuntu`环境

使用命令安装好`gcc`,`mpich`

```bash
sudo apt-get update
sudo apt-get install mpich
```

安装好之后查看版本

```bash
mpiexec --version
```



## 简单的MPIC程序



```c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);

    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);

    int world_size;
    MPI_Comm_size(MPI_COMM_WORLD, &world_size);

    printf("Hello world from processor %d of %d\n", world_rank, world_size);

    MPI_Finalize();
    return 0;
}

```

编译程序

```bash
mpicc -o hello_world helloworld.c
```

运行程序

```bash
mpiexec -n 4 ./hello_world
```

运行结果

![image-20240618114906236](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406181149513.png?imageSlim)

## 两种通信方式

MPI有两种通信方式

- 点对点通信

  一个进程发送消息给另一个指定的进程，或者一个进程接受一个进程的消息。

- 集体通信(collective communication)

  一个进程发送消息给所有进程，或者所有进程将各自的数据收集到一个进程中。

点对点通信类似于一对一的聊天。集体通信类似于群聊。



这两种通信的分别实现：

### 1.点对点通信

点对点通信分为:

1. 阻塞通信
1. 非阻塞通信
1. 同步通信

#### 阻塞通信

阻塞通信又细分为:

1. 标准通信
1. 就绪通信
1. 同步通信

在阻塞通信中，发送或接收操作在完成之前不会返回。这意味着发送方会等待消息被发送完毕，接收方会等待消息被接收完毕。



**标准通信:**

- `MPI_Send(&data,count,datatype,dest,tag,comm)`（发送过程）
  - `data`:发送的数据
  - `count`：数据的数量
  - `datatype`：数据类型
  - `dest`：目标进程的排名(rank)
  - `tag`：消息的标签，**整数类型**
  - `comm`：通信器
- `MPI_Recv(&data,count,datatype,source,tag,comm,&status)`（接收过程）
  - `data`:接受数据的缓冲区
  - `count`:数据的数量
  - `datatype`:数据类型
  - `source`:发送进程的排名
  - `tag`:消息标签，**整数类型**
  - `comm`:通信器
  - `status`:状态对象，包含消息的信息。



**就绪通信:**

就绪通信假设接收方已经准备好接收消息，如果接收方未准备好，发送操作将导致错误。

下面是发送过程:

```c
int MPI_Rsend(const void *buf,
              int count,
              MPI_Datatype datatype, 
              int dest, 
              int tag, 
              MPI_Comm comm);

```

接收过程和标准通信一样



**同步通信:**

同步通信确保消息在发送操作返回之前已被接收方接收。发送方会等待接收方确认接收消息后才返回。

```c
int MPI_Ssend(const void *buf,
              int count,
              MPI_Datatype datatype,
              int dest,
              int tag,
              MPI_Comm comm);

```





#### 非阻塞通信

在非阻塞通信中，发送或接收操作立即返回，不必等待消息发送或接收完毕。进程可以在等待通信完成的**同时进行其他工作**。

发送过程

```c
int MPI_Isend(const void *buf,
              int count,
              MPI_Datatype datatype, 
              int dest, 
              int tag, 
              MPI_Comm comm, 
              MPI_Request *request);

```

接收过程

```c
int MPI_Irecv(void *buf, 
              int count,
              MPI_Datatype datatype,
              int source,
              int tag, 
              MPI_Comm comm, 
              MPI_Request *request);

```



### 2.集体通信

![image-20240618125341518](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406181253261.png?imageSlim)



#### 广播(broadcast)

将一个进程的数据发送到所有其他进程。

如图所示：![image-20240618125449450](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406181254528.png?imageSlim)

```c
int MPI_Bcast(void *buffer, 
              int count,
              MPI_Datatype datatype, 
              int root,
              MPI_Comm comm);
```



`buffer`：存储数据的缓存区

`count`:数据项的数量

`datatype`:数据类型

`root`:根进程的排名

`comm`:通信器





#### 收集(gather)

将各个进程的数据收集到一个进程。

![image-20240618125721231](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406181257357.png?imageSlim)

```c
int MPI_Gather(const void *sendbuf, 
               int sendcount, 
               MPI_Datatype sendtype,
               void *recvbuf, 
               int recvcount, 
               MPI_Datatype recvtype,
               int root, 
               MPI_Comm comm);
```



  - `sendbuf`：发送数据的缓冲区。
    
  - `sendcount`：每个进程发送的数据项数量。
    
  - `sendtype`：发送数据的类型。
    
  - `recvbuf`：接收数据的缓冲区（仅根进程使用）。
    
  - `recvcount`：根进程使用接收的数据项数量。
    
  - `recvtype`：根进程接收数据的类型。
    
  - `root`：接收数据的根进程的排名。
    
  - `comm`：通信器。

**MPI_Scatterv**：允许向各个进程发送不同长度的数据

```c
int MPI_Scatterv(void *sendbuf, 
                 int *sendcounts, 
                 int *displs,
                 MPI_Datatype sendtype,
                 void *recvbuf, 
                 int recvcount, 
                 MPI_Datatype recvtype, 
                 int root, 
                 MPI_Comm comm);

```





#### 分发(scatter)

将一个进程的数据分发到其他进程

![image-20240618130849558](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406181308520.png?imageSlim)

```c
int MPI_Scatter(const void *sendbuf, 
                int sendcount, 
                MPI_Datatype sendtype, 
                void *recvbuf, 
                int recvcount, 
                MPI_Datatype recvtype, 
                int root, MPI_Comm comm);

```

`sendbuf`：发送数据的缓冲区（仅根进程使用）。

`sendcount`：每个进程发送的数据项数量（仅根进程使用）。

`sendtype`：发送数据的类型（仅根进程使用）。

`recvbuf`：接收数据的缓冲区。

`recvcount`：每个进程接收的数据项数量。

`recvtype`：接收数据的类型。

`root`：发送数据的根进程的排名。

`comm`：通信器。



**MPI_Scatterv**：允许向各个进程发送**不同长度**的数据。

```c
int MPI_Scatterv(void *sendbuf, 
                 int *sendcounts, 
                 int *displs,
                 MPI_Datatype sendtype, 
                 void *recvbuf,
                 int recvcount, 
                 MPI_Datatype recvtype, 
                 int root,
                 MPI_Comm comm);

```

#### 规约(reduce)

![image-20240629183551359](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406291835560.png?imageSlim)

对**组内**所有进程的数据进行某种**规约**运算后，将结果保存在根进程中.

```c
int MPI_Reduce(const void *sendbuf, 
               void *recvbuf, 
               int count, 
               MPI_Datatype datatype,
               MPI_Op op, 
               int root,
               MPI_Comm comm)

```



#### 全收集(allgather)

将各个进程的数据收集到**所有进程**。

![image-20240618131254415](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406181312285.png?imageSlim)

```c
int MPI_Allgather(const void *sendbuf,
                  int sendcount, 
                  MPI_Datatype sendtype, 
                  void *recvbuf, 
                  int recvcount,
                  MPI_Datatype recvtype, 
                  MPI_Comm comm);

```

`sendbuf`：发送数据的缓冲区。

`sendcount`：每个进程发送的数据项数量。

`sendtype`：发送数据的类型。

`recvbuf`：接收数据的缓冲区。

`recvcount`：每个进程接收的数据项数量。

`recvtype`：接收数据的类型。

`comm`：通信器。



**MPI_Allgatherv**：允许执行变长度的全收集操作

```c
int MPI_Allgatherv(const void *sendbuf,
                   int sendcount, 
                   MPI_Datatype sendtype, 
                   void *recvbuf, 
                   const int *recvcounts,
                   const int *displs,
                   MPI_Datatype recvtype,
                   MPI_Comm comm);

```



#### 全归约(allreduce)

![image-20240629184535267](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406291845613.png?imageSlim)

 对所有进程的数据进行归约操作，并将结果分发到所有进程。

```c
int MPI_Allreduce(const void *sendbuf, 
                  void *recvbuf, 
                  int count, 
                  MPI_Datatype datatype,
                  MPI_Op op, 
                  MPI_Comm comm);

```

`sendbuf`：发送数据的缓冲区。

`recvbuf`：接收归约结果的缓冲区。

`count`：每个进程发送的数据项数量。

`datatype`：数据类型。

`op`：归约操作（如 `MPI_SUM`, `MPI_MAX`）。

`comm`：通信器。

#### 扫描规约(scan)

![image-20240629184606778](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406291846208.png?imageSlim)

**MPI_Scan**：逐级执行规约操作，即进程i对进程0到i执行规约运算

```c
int MPI_Scan(const void *sendbuf, 
             void *recvbuf, 
             int count, 
             MPI_Datatype datatype, 
             MPI_Op op,
             MPI_Comm comm);

```

#### 前缀扫描(exscan)

![image-20240629185155070](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406291851335.png?imageSlim)

前缀规约对进程集合进行前缀计算，但不包括每个进程自身的值。

具体来说，对于进程 `i`，其接收的结果是第0,1.,..,i-1个进程发送缓冲区的规约结果。进程 `0` 的接收缓冲区未定义，因为它没有前缀进程。

```c
int MPI_Exscan(const void *sendbuf, 
               void *recvbuf,
               int count, 
               MPI_Datatype datatype, 
               MPI_Op op, 
               MPI_Comm comm);

```



#### 屏障(barrier)

![image-20240629185745915](https://tomslong-imgs-1323348731.cos.ap-guangzhou.myqcloud.com/img/202406291857985.png?imageSlim)

**MPI_Barrier**：实施同步操作，确保所有进程在此点上同步

```c
int MPI_Barrier(MPI_Comm comm);

```



## 组与通信子

### 组

**组是什么**

组是一组有序的进程集合.

**组有什么用**

1. 便于进程的管理和组织.

通过将进程分组,可以简化进程间的通信和协作.

2. 定义通信范围/通信上下文

组用于限定通信的范围，使得通信操作只在指定的进程集合中进行，避免干扰其他进程。

3. 进行集合操作

可以在特定的进程集合内进行高效的集合通信.



## 一些问题

1. 为什么要有`tag`标签机制的存在？

tag标签的作用就是用来**区分消息**的,如果是不同进程之间，只传送一个消息，只需要通过接收进程和发送进程的排名就能区分消息，但是如果进程间传送多个消息呢？怎么区分这些消息？所以标签在这里就发挥出了作用。

2. 为什么要分标准模式,就绪模式,同步模式?

   因为要满足不同情况下的需求.

 标准模式（Standard Mode）

- **实际用处**：用于大多数常见的通信需求，如在编写简单的并行程序时。
- **优势**：易于使用，适合初学者和一般应用。

 同步模式（Synchronous Mode）

- **实际用处**：需要确保消息被接收方确实接收时，如在安全关键系统中。
- **优势**：高可靠性，适用于严格同步的场景。

 就绪模式（Ready Mode）

- **实际用处**：在已知接收方已准备好时使用，如在固定通信模式下。
- **优势**：高效，减少开销，适用于优化性能的场景。

 非阻塞模式（Non-blocking Mode）

- **实际用处**：需要重叠通信和计算的高性能计算场景。
- **优势**：提高资源利用率和并行效率。